{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week43_Nuclei_Overview_to_Submission.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN3uDR5tCEjj/sQazrCCepj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## [Kaggle Clone Coding] 2018 Data Science Bowl\n","- [2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018)\n","- [Nuclei Overview to Submission](https://www.kaggle.com/kmader/nuclei-overview-to-submission)\n","  \n","- Task : 분할된 세포의 핵 이미지 기반 object segmentation\n","---"],"metadata":{"id":"QHbxSK5TO5sr"}},{"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from glob import glob\n","import os\n","from skimage.io import imread\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","%cd /content/drive/MyDrive/Kaggle/kaggle/\n","dsb_data_dir = '/'\n","stage_label = 'stage1'"],"metadata":{"id":"Rcrwsy_KO5cL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Read labels"],"metadata":{"id":"mRgxUqUmPHY-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R15AYXYWO4qe"},"outputs":[],"source":["train_labels = pd.read_csv(os.path.join(dsb_data_dir,'{}_train_labels.csv'.format(stage_label)))\n","train_labels['EncodedPixels'] = train_labels['EncodedPixels'].map(lambda ep: [int(x) for x in ep.split(' ')])\n","train_labels.sample(3)"]},{"cell_type":"markdown","source":["#### Load Images"],"metadata":{"id":"99wfHm3NPNU7"}},{"cell_type":"code","source":["all_images = glob(os.path.join(dsb_data_dir, 'stage1_*', '*', '*', '*'))\n","img_df = pd.DataFrame({'path': all_images})\n","img_id = lambda in_path: in_path.split('/')[-3]\n","img_type = lambda in_path: in_path.split('/')[-2]\n","img_group = lambda in_path: in_path.split('/')[-4].split('_')[1]\n","img_stage = lambda in_path: in_path.split('/')[-4].split('_')[0]\n","img_df['ImageId'] = img_df['path'].map(img_id)\n","img_df['ImageType'] = img_df['path'].map(img_type)\n","img_df['TrainingSplit'] = img_df['path'].map(img_group)\n","img_df['Stage'] = img_df['path'].map(img_stage)\n","img_df.sample(2)"],"metadata":{"id":"H5Tzx64qPPmk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Crate Training Data"],"metadata":{"id":"LRELFaSSPYAN"}},{"cell_type":"code","source":["%%time\n","train_df = img_df.query('TrainingSplit==\"train\"')\n","train_rows = []\n","group_cols = ['Stage', 'ImageId']\n","for n_group, n_rows in train_df.groupby(group_cols):\n","    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, n_group)}\n","    c_row['masks'] = n_rows.query('ImageType == \"masks\"')['path'].values.tolist()\n","    c_row['images'] = n_rows.query('ImageType == \"images\"')['path'].values.tolist()\n","    train_rows += [c_row]\n","train_img_df = pd.DataFrame(train_rows)    \n","IMG_CHANNELS = 3\n","def read_and_stack(in_img_list):\n","    return np.sum(np.stack([imread(c_img) for c_img in in_img_list], 0), 0)/255.0\n","train_img_df['images'] = train_img_df['images'].map(read_and_stack).map(lambda x: x[:,:,:IMG_CHANNELS])\n","train_img_df['masks'] = train_img_df['masks'].map(read_and_stack).map(lambda x: x.astype(int))\n","train_img_df.sample(1)"],"metadata":{"id":"qGLY9ddYPbLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_img = 6\n","fig, m_axs = plt.subplots(2, n_img, figsize = (12, 4))\n","for (_, c_row), (c_im, c_lab) in zip(train_img_df.sample(n_img).iterrows(), \n","                                     m_axs.T):\n","    c_im.imshow(c_row['images'])\n","    c_im.axis('off')\n","    c_im.set_title('Microscope')\n","    \n","    c_lab.imshow(c_row['masks'])\n","    c_lab.axis('off')\n","    c_lab.set_title('Labeled')"],"metadata":{"id":"C3JQwAIqPcoh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 분포를 확인해 보았을 때, 몇개의 군집을 확인할 수 있었음\n","\n","train_img_df['Red'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]))\n","train_img_df['Green'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,1]))\n","train_img_df['Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,2]))\n","train_img_df['Gray'] = train_img_df['images'].map(lambda x: np.mean(x))\n","train_img_df['Red-Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]-x[:,:,2]))\n","sns.pairplot(train_img_df[['Gray', 'Red', 'Green', 'Blue', 'Red-Blue']])"],"metadata":{"id":"jLa0wil4P0_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 차원 확인\n","\n","train_img_df['images'].map(lambda x: x.shape).value_counts()"],"metadata":{"id":"AOdzcV3yQA_v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Build Simple CNN"],"metadata":{"id":"v62cB1CnQFO9"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import BatchNormalization, Conv2D, UpSampling2D, Lambda\n","simple_cnn = Sequential()\n","simple_cnn.add(BatchNormalization(input_shape = (None, None, IMG_CHANNELS), \n","                                  name = 'NormalizeInput'))\n","simple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n","simple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n","# use dilations to get a slightly larger field of view\n","simple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\n","simple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\n","simple_cnn.add(Conv2D(32, kernel_size = (3,3), dilation_rate = 3, padding = 'same'))\n","\n","# the final processing\n","simple_cnn.add(Conv2D(16, kernel_size = (1,1), padding = 'same'))\n","simple_cnn.add(Conv2D(1, kernel_size = (1,1), padding = 'same', activation = 'sigmoid'))\n","simple_cnn.summary()"],"metadata":{"id":"4-oQaORDQIB0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Loss"],"metadata":{"id":"kVXa18kdQJVI"}},{"cell_type":"code","source":["from keras import backend as K\n","smooth = 1.\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","simple_cnn.compile(optimizer = 'adam', \n","                   loss = dice_coef_loss, \n","                   metrics = [dice_coef, 'acc', 'mse'])"],"metadata":{"id":"9xdY7dQrQKcS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Train"],"metadata":{"id":"ft2P6e9OQLln"}},{"cell_type":"code","source":["def simple_gen():\n","    while True:\n","        for _, c_row in train_img_df.iterrows():\n","            yield np.expand_dims(c_row['images'],0), np.expand_dims(np.expand_dims(c_row['masks'],-1),0)\n","\n","simple_cnn.fit_generator(simple_gen(), \n","                         steps_per_epoch=train_img_df.shape[0],\n","                        epochs = 3)"],"metadata":{"id":"Nq2d7NCeQMrc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Testing"],"metadata":{"id":"pqy111k-QN4O"}},{"cell_type":"code","source":["%%time\n","test_df = img_df.query('TrainingSplit==\"test\"')\n","test_rows = []\n","group_cols = ['Stage', 'ImageId']\n","for n_group, n_rows in test_df.groupby(group_cols):\n","    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, n_group)}\n","    c_row['images'] = n_rows.query('ImageType == \"images\"')['path'].values.tolist()\n","    test_rows += [c_row]\n","test_img_df = pd.DataFrame(test_rows)    \n","\n","test_img_df['images'] = test_img_df['images'].map(read_and_stack).map(lambda x: x[:,:,:IMG_CHANNELS])\n","print(test_img_df.shape[0], 'images to process')\n","test_img_df.sample(1)"],"metadata":{"id":"0LFOVtgsQPfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","test_img_df['masks'] = test_img_df['images'].map(lambda x: simple_cnn.predict(np.expand_dims(x, 0))[0, :, :, 0])"],"metadata":{"id":"SHnyDjAjQQdy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Visualize Prediction"],"metadata":{"id":"nbomL_M3QQzl"}},{"cell_type":"code","source":["n_img = 3\n","from skimage.morphology import closing, opening, disk\n","def clean_img(x):\n","    return opening(closing(x, disk(1)), disk(3))\n","fig, m_axs = plt.subplots(3, n_img, figsize = (12, 6))\n","for (_, d_row), (c_im, c_lab, c_clean) in zip(test_img_df.sample(n_img).iterrows(), \n","                                     m_axs):\n","    c_im.imshow(d_row['images'])\n","    c_im.axis('off')\n","    c_im.set_title('Microscope')\n","    \n","    c_lab.imshow(d_row['masks'])\n","    c_lab.axis('off')\n","    c_lab.set_title('Predicted')\n","    \n","    c_clean.imshow(clean_img(d_row['masks']))\n","    c_clean.axis('off')\n","    c_clean.set_title('Clean')"],"metadata":{"id":"X2lO_N3HQUX1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Check RLE"],"metadata":{"id":"E0HMrneCQVzs"}},{"cell_type":"code","source":["from skimage.morphology import label # label regions\n","def rle_encoding(x):\n","    '''\n","    x: numpy array of shape (height, width), 1 - mask, 0 - background\n","    Returns run length as list\n","    '''\n","    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n","    run_lengths = []\n","    prev = -2\n","    for b in dots:\n","        if (b>prev+1): run_lengths.extend((b+1, 0))\n","        run_lengths[-1] += 1\n","        prev = b\n","    return run_lengths\n","\n","def prob_to_rles(x, cut_off = 0.5):\n","    lab_img = label(x>cut_off)\n","    if lab_img.max()<1:\n","        lab_img[0,0] = 1 # ensure at least one prediction per image\n","    for i in range(1, lab_img.max()+1):\n","        yield rle_encoding(lab_img==i)"],"metadata":{"id":"e_YPERopQXN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, train_rle_row = next(train_img_df.tail(5).iterrows()) \n","train_row_rles = list(prob_to_rles(train_rle_row['masks']))\n","\n","tl_rles = train_labels.query('ImageId==\"{ImageId}\"'.format(**train_rle_row))['EncodedPixels']"],"metadata":{"id":"2EDLZFNcQYfn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["match, mismatch = 0, 0\n","for img_rle, train_rle in zip(sorted(train_row_rles, key = lambda x: x[0]), \n","                             sorted(tl_rles, key = lambda x: x[0])):\n","    for i_x, i_y in zip(img_rle, train_rle):\n","        if i_x == i_y:\n","            match += 1\n","        else:\n","            mismatch += 1\n","print('Matches: %d, Mismatches: %d, Accuracy: %2.1f%%' % (match, mismatch, 100.0*match/(match+mismatch)))"],"metadata":{"id":"QgFeJRuEQaLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate rle for all masks\n","\n","test_img_df['rles'] = test_img_df['masks'].map(clean_img).map(lambda x: list(prob_to_rles(x)))\n","\n","out_pred_list = []\n","for _, c_row in test_img_df.iterrows():\n","    for c_rle in c_row['rles']:\n","        out_pred_list+=[dict(ImageId=c_row['ImageId'], \n","                             EncodedPixels = ' '.join(np.array(c_rle).astype(str)))]\n","out_pred_df = pd.DataFrame(out_pred_list)\n","print(out_pred_df.shape[0], 'regions found for', test_img_df.shape[0], 'images')\n","out_pred_df.sample(3)\n","\n","out_pred_df[['ImageId', 'EncodedPixels']].to_csv('predictions.csv', index = False)"],"metadata":{"id":"9bPHU8KUQbmI"},"execution_count":null,"outputs":[]}]}